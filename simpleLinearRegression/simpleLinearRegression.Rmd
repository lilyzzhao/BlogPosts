---
title: "'Simple' Linear Regression"
output: html_notebook
---

Simple linear regression models the relationship between a dependent variable and an explanatory variable. For example, let's take a very real and 100% legitimate data set (honestly no need to Google it) involving the number of cats a person should have depending on their age. 

Simple linear regression takes the form 

$$y = \beta_0 + \beta_1x + \epsilon$$

with $\beta_0$ and $\beta_1$ representing unknown model parameters which we'll want to estimate.  

$\beta_0$ is generally referred to as the **intercept** and $\beta_1$ as the **slope** of the linear relationship. We want to find $\beta$ values, or coefficients, that minimize the error term of the equation, $\epsilon$. The smaller our error terms, the closer the data fits our linear relationship. Spec

We can write the linear model equation in terms of the observations:

$$y_i = \beta_0 + \beta_1x_i, i = 1, 2, ...n$$ 




```{r}
# Fit a linear model using lm.
fit <- lm(cats ~ age, data = catsData)
# Print summary of linear model.
summary(fit)
```






